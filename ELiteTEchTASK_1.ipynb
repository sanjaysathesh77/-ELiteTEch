{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gVqaY8wNoLud"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Extract\n",
        "def load_data(file_path):\n",
        "    print(f\"Loading data from: {file_path}\")\n",
        "    return pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "TBcg3G7coVX0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Step 2: Transform\n",
        "def preprocess_data(df):\n",
        "    print(\"Starting preprocessing...\")\n",
        "\n",
        "    # Separate features and target (example: assume last column is target)\n",
        "    X = df.iloc[:, :-1]\n",
        "    y = df.iloc[:, -1]\n",
        "\n",
        "    # Identify column types\n",
        "    num_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "    cat_cols = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "    # Pipelines for transformation\n",
        "    numeric_pipeline = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='mean')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "\n",
        "    categorical_pipeline = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "    ])\n",
        "\n",
        "    # Combine them into a ColumnTransformer\n",
        "    preprocessor = ColumnTransformer(transformers=[\n",
        "        ('num', numeric_pipeline, num_cols),\n",
        "        ('cat', categorical_pipeline, cat_cols)\n",
        "    ])\n",
        "\n",
        "    # Apply the transformations\n",
        "    X_transformed = preprocessor.fit_transform(X)\n",
        "\n",
        "    return X_transformed, y, preprocessor\n"
      ],
      "metadata": {
        "id": "2jJvOkipomfI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Load\n",
        "def save_transformed_data(X, y, output_dir='output'):\n",
        "    print(\"Saving transformed data...\")\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    X_df = pd.DataFrame(X.toarray() if hasattr(X, 'toarray') else X)\n",
        "    y_df = pd.DataFrame(y)\n",
        "\n",
        "    X_df.to_csv(os.path.join(output_dir, 'features.csv'), index=False)\n",
        "    y_df.to_csv(os.path.join(output_dir, 'labels.csv'), index=False)\n",
        "    print(f\"Data saved in '{output_dir}' directory.\")"
      ],
      "metadata": {
        "id": "n6niTNZ9pDNf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main Pipeline Function\n",
        "def run_etl_pipeline(input_csv):\n",
        "    df = load_data(input_csv)\n",
        "    X, y, _ = preprocess_data(df)\n",
        "    save_transformed_data(X, y)"
      ],
      "metadata": {
        "id": "rgkXHSNrpOoh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Run the Pipeline\n",
        "if __name__ == \"__main__\":\n",
        "    # Replace this with your own data file\n",
        "    run_etl_pipeline(\"/content/train.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ejNY7edpW42",
        "outputId": "393282ef-0cab-44ee-b30d-eb632cab04e6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data from: /content/train.csv\n",
            "Starting preprocessing...\n",
            "Saving transformed data...\n",
            "Data saved in 'output' directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ddZ1bL2ipcyU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}